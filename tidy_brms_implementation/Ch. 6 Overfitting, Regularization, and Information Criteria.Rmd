---
title: "Ch. 6 Overfitting, Regularization, and Information Criteria"
author: "A Solomon Kurz"
date: "3/15/2018"
output: html_document
editor_options: 
  chunk_output_type: inline
---

###6.1.1. More parameters always impove fit.

We'll start of by making the data with brain size and body size for seven `species`.

```{r, warning = F, message = F}
library(tidyverse)


(
  d <- 
  tibble(species = c("afarensis", "africanus", "habilis", "boisei",
                     "rudolfensis", "ergaster", "sapiens"), 
         brain = c(438, 452, 612, 521, 752, 871, 1350), 
         mass = c(37.0, 35.5, 34.5, 41.5, 55.5, 61.0, 53.5))
  )
```

Here's our version of Figure 6.2.

```{r, fig.width = 3.5, fig.height = 3}
# install.packages("ggrepel", depencencies = T)
library(ggrepel)

set.seed(438) #  This makes the geom_text_repel() part reproducible
d %>%
  ggplot(aes(x =  mass, y = brain)) +
  theme_classic() +
  geom_point(color = "plum") +
  geom_text_repel(size = 3, color = "plum4", family = "Courier", mapping = aes(label = species)) +
  coord_cartesian(xlim = 30:65) +
  labs(x = "body mass (kg)",
       y = "brain volume (cc)",
       subtitle = "Average brain volume by body mass\nfor six hominin species") +
  theme(text = element_text(family = "Courier"))
```

I’m not going to bother with models `m6.1` through `m6.7` They were all done with the frequentist `lm()` function, which yields model estimates with OLS. Since the primary job of this manuscript is to convert rethinking code to brms code, those models provide nothing to convert.

Onward. 

##6.2. Information theory and model performance

###6.2.2. Information and uncertainty.

In the "Overthinking: Computing deviance." section McElreath does just that.
Here is how to do so with brms.

```{r, message = F, warning = F}
# data manipulation
d <-
  d %>%
  mutate(mass.s = (mass - mean(mass))/sd(mass))

library(brms)

# Here we specify our starting values
Inits <- list(Intercept = mean(d$brain),
              mass.s = 0,
              sigma = sd(d$brain))

InitsList <-list(Inits, Inits, Inits, Inits)

# The model
b6.8 <- 
  brm(data = d, family = gaussian,
      brain ~ 1 + mass.s,
      prior = c(set_prior("normal(0, 1000)", class = "Intercept"),
                set_prior("normal(0, 1000)", class = "b"),
                set_prior("cauchy(0, 10)", class = "sigma")),
      chains = 4, iter = 2000, warmup = 1000, cores = 4,
      inits = InitsList)  # Here we put our start values in the brm() function

print(b6.8)
```

**Details about `inits`**: You don’t have to specify your `inits` lists outside of the `brm()` function the way we did, here. This is just how I currently prefer to do it. When you specify start values for the parameters in your Stan models, you need to do so with a list of lists. You need as many lists as HMC chains—four in this example. And then you put your—in this case—four lists inside a list. Lists within lists. Also, we were lazy and specified the same start values across all our chains. You can mix them up across chains if you want.

Anyway, the brms function `log_lik()` returns a matrix. Each occasion gets a column and each HMC chain iteration gets a row.

```{r}
dfLL <-
  b6.8 %>%
  log_lik() %>%
  as_tibble()

dfLL %>%
  glimpse()
```

Deviance is the sum of the occasion-level LLs multiplied by -2.

```{r}



dfLL <-
  dfLL %>%
  mutate(sums     = rowSums(.),
         deviance = -2*sums)
```

Because we used HMC, deviance is a distribution rather than a single number.

```{r, fig.width = 3.75, fig.height = 2.5}
quantile(dfLL$deviance, c(.025, .5, .975))

ggplot(data = dfLL, aes(x = deviance)) +
  theme_classic() +
  geom_density(fill = "plum", size = 0) +
  geom_vline(xintercept = quantile(dfLL$deviance, c(.025, .5, .975)),
             color = "plum4", linetype = c(2, 1, 2)) +
  scale_x_continuous(breaks = quantile(dfLL$deviance, c(.025, .5, .975)),
                     labels = c(95, 98, 105)) +
  scale_y_continuous(NULL, breaks = NULL) +
  labs(title = "The deviance distribution",
       subtitle = "The dotted lines are the 95% intervals and\nthe solid line is the median.") +
  theme(text = element_text(family = "Courier"))
```

##6.3. Regularization

In case you were curious, here's how you might do Figure 6.8 with ggplot2. All the action is in the `geom_line()` portions. The rest is window dressing.

```{r, fig.width = 3, fig.height = 3}
tibble(x = seq(from = - 3.5, 
               to = 3.5, 
               by = .01)) %>%
  
  ggplot(aes(x = x)) +
  theme_classic() +
  geom_ribbon(aes(ymin = 0, ymax = dnorm(x, mean = 0, sd = 1)), 
              fill = "plum", alpha = 1/8) +
  geom_ribbon(aes(ymin = 0, ymax = dnorm(x, mean = 0, sd = 0.5)), 
              fill = "plum", alpha = 1/8) +
  geom_ribbon(aes(ymin = 0, ymax = dnorm(x, mean = 0, sd = 0.2)), 
              fill = "plum", alpha = 1/8) +
  geom_line(aes(y = dnorm(x, mean = 0, sd = 1)), 
            linetype = 2, color = "plum4") +
  geom_line(aes(y = dnorm(x, mean = 0, sd = 0.5)), 
            size = .25, color = "plum4") +
  geom_line(aes(y = dnorm(x, mean = 0, sd = 0.2)), 
            color = "plum4") +
  scale_y_continuous(NULL, breaks = NULL) +
  labs(x = "parameter value") +
  coord_cartesian(xlim = c(-3, 3)) +
  theme(text = element_text(family = "Courier"))
```

###6.4.1. DIC.

In the "Overthinking: WAIC calculation." section McElreath goes over just that.
Here is how to fit the model in brms.

```{r, message = FALSE, warning = FALSE}
data(cars)

df <- tibble(name = c("model_frac", "model"), data = list(sample_frac(cars, size = 0.4), cars))

# df2 <- df %>% mutate(model = purrr::map(.x = data, .f = ~ brm(data = .x, family = gaussian,
#       dist ~ 1 + speed,
#       prior = c(set_prior("normal(0, 100)", class = "Intercept"),
#                 set_prior("normal(0, 10)", class = "b"),
#                 set_prior("cauchy(0, 1)", class = "sigma")),
#       chains = 4, iter = 2000, warmup = 1000, cores = 4)))

df3 <- df %>% mutate(model = data %>% purrr::map( ~ brm(data = .x, family = gaussian,
      dist ~ 1 + speed,
      prior = c(set_prior("normal(0, 100)", class = "Intercept"),
                set_prior("normal(0, 10)", class = "b"),
                set_prior("uniform(0, 30)", class = "sigma")),
      chains = 2, iter = 2000, warmup = 1000, cores = 2))
      )



# b <-
#   brm(data = cars, family = gaussian,
#       dist ~ 1 + speed,
#       prior = c(set_prior("normal(0, 100)", class = "Intercept"),
#                 set_prior("normal(0, 10)", class = "b"),
#                 set_prior("uniform(0, 30)", class = "sigma")),
#       chains = 4, iter = 2000, warmup = 1000, cores = 4)

# b_v2 <- update(b, formula. = dist ~ 1 + speed,
#                newdata = sample_frac(cars, size = 0.4))

df3 %>% pull(model) %>% map(print)


               

```
```{r}
calc_lppd <-function(brmsfit){brmsfit %>% 
  log_lik %>% 
  exp %>% 
  as_tibble %>% 
  summarise_all(mean) %>% 
  log %>% 
  sum}

# df3 <- df3 %>% mutate(lppd = model %>% map(compose(as_tibble, log_lik)) %>% map(summarise_all, compose(log,mean, exp)) %>% map_dbl(sum))# %>% sum )
# df3 <- df3 %>% mutate(lppd2 = model %>% map_dbl(compose(sum,partial(summarise_all, .funs = compose(log,mean, exp)), as_tibble, log_lik)))
df3 <- df3 %>% mutate(
  lppd3 = model %>% map_dbl(
    . %>% 
      log_lik %>% 
      exp %>% 
      as_tibble %>% 
      summarise_all(mean) %>% 
      log %>% 
      sum)
  )

df3 <- df3 %>% mutate(
  lppd4 = model %>% map_dbl(calc_lppd)
  )

df3
```
In brms, you get the loglikelihood with `log_lik()`.

```{r, results = "hide"}
dfLL <-
  df3 %>% filter(name == "model") %>% pull(model) %>% first() %>% 
  # b %>%
  log_lik() %>%
  as_tibble()

dfLL %>%
  glimpse()
```

Computing the lppd, the "Bayesian deviance", takes a bit of leg work.

```{r}
dfmean <-
  dfLL %>%
  exp() %>%
  summarise_all(mean) %>%
  gather(key, means) %>%
  select(means) %>%
  log()

my_lppd <- dfLL %>%
  # exp() %>%
  summarise_all(compose(log,mean, exp)) %>% sum 


lppd <-
  dfmean %>%
  sum()

lppd
```

Comupting the effective number of parameters, *p*~WAIC~, isn't much better.

```{r}
dfvar <-
  dfLL %>%
  summarise_all(var) %>%
  gather(key, vars) %>%
  select(vars) 

pwaic <-
  dfvar %>%
  sum()

pwaic
dfvar

df3 <- df3 %>% mutate(
  pwaic = model %>% map_dbl(
    . %>% 
      log_lik %>% 
      as_tibble %>% 
      summarise_all(var) %>% 
      sum)
  )

df3


```

Finally, here's what we've been working so hard for: our hand calculated WAIC value. Compare it to the value returned by the brms `waic()` function.

```{r, message = F, warning = F}
-2*(lppd - pwaic)

waic(df3 %>% filter(name == "model") %>% pull(model) %>% first())

df3 %>% mutate(waic = -2*(lppd3 - pwaic))

waic(b)
```
```{r}


b %>% tidybayes::as_sample_tibble()
```
Here's how we get the WAIC standard error.

```{r}
dfmean %>%
  mutate(waic_vec = -2*(means - dfvar$vars)) %>%
  summarise(waic_se = (var(waic_vec)*nrow(dfmean)) %>% sqrt())
```

###6.5.1. Model comparison. 

Getting the `milk` data from earlier in the text.

```{r, message = F}
library(rethinking)

data(milk)
d <- 
  milk %>%
  filter(complete.cases(.))
rm(milk)

d <-
  d %>%
  mutate(neocortex = neocortex.perc/100)

dim(d)
```

Fitting our competing models in brms.

```{r, message = F, warning = F}
detach(package:rethinking, unload = T)
library(brms)

Inits <- list(Intercept = mean(d$kcal.per.g),
              sigma = sd(d$kcal.per.g))

InitsList <-list(Inits, Inits, Inits, Inits)

b6.11 <- 
  brm(data = d, family = gaussian,
      kcal.per.g ~ 1,
      prior = c(set_prior("uniform(-1000, 1000)", class = "Intercept"),
                set_prior("uniform(0, 100)", class = "sigma")),
      chains = 4, iter = 2000, warmup = 1000, cores = 4,
      inits = InitsList)

Inits <- list(Intercept = mean(d$kcal.per.g),
              neocortex = 0,
              sigma = sd(d$kcal.per.g))

b6.12 <- 
  brm(data = d, family = gaussian,
      kcal.per.g ~ 1 + neocortex,
      prior = c(set_prior("uniform(-1000, 1000)", class = "Intercept"),
                set_prior("uniform(-1000, 1000)", class = "b"),
                set_prior("uniform(0, 100)", class = "sigma")),
      chains = 4, iter = 2000, warmup = 1000, cores = 4,
      inits = InitsList)

Inits <- list(Intercept = mean(d$kcal.per.g),
              `log(mass)` = 0,
              sigma = sd(d$kcal.per.g))

b6.13 <- 
  brm(data = d, family = gaussian,
      kcal.per.g ~ 1 + log(mass),
      prior = c(set_prior("uniform(-1000, 1000)", class = "Intercept"),
                set_prior("uniform(-1000, 1000)", class = "b"),
                set_prior("uniform(0, 100)", class = "sigma")),
      chains = 4, iter = 2000, warmup = 1000, cores = 4,
      inits = InitsList)

Inits <- list(Intercept = mean(d$kcal.per.g),
              neocortex = 0,
              `log(mass)` = 0,
              sigma = sd(d$kcal.per.g))

b6.14 <- 
  brm(data = d, family = gaussian,
      kcal.per.g ~ 1 + neocortex + log(mass),
      prior = c(set_prior("uniform(-1000, 1000)", class = "Intercept"),
                set_prior("uniform(-1000, 1000)", class = "b"),
                set_prior("uniform(0, 100)", class = "sigma")),
      chains = 4, iter = 2000, warmup = 1000, cores = 4,
      inits = InitsList)
```

####6.5.1.1. Comparing WAIC values.

In brms, you can get a model's WAIC value with either `WAIC()` or `waic()`.

```{r, warning = F, message = F}
WAIC(b6.14)

waic(b6.14)
```

There are two basic ways to compare WAIC values from multiple models. In the first, you add more model names into the `waic()` function.

```{r, message = F, warning = F}
waic(b6.11, b6.12, b6.13, b6.14)
```

Alternatively, you first save each model's `waic()` output in its own object, and then feed to those objects into `compare_ic()`.

```{r, message = F, warning = F}
w.b6.11 <- waic(b6.11)
w.b6.12 <- waic(b6.12)
w.b6.13 <- waic(b6.13)
w.b6.14 <- waic(b6.14)

compare_ic(w.b6.11, w.b6.12, w.b6.13, w.b6.14) # %>% map("waic")
```

I'm not aware of a convenient way to plot the WAIC comparisons of brms models the way McElreath does with rethinking. However, one can get the basic comparison plot with a little data processing. It helps to examine the structure of your WAIC objects. For example:

```{r}
glimpse(w.b6.11)
```

We can index the point estimate for model `b6.11`'s WAIC as `w.b6.11$waic` and the standard error as `w.b6.11$se_waic`. 

```{r, message = F, warning = F}
w.b6.11$waic

w.b6.11$se_waic
```

Armed with that information, we can make a data structure with those bits from all our models and then make a plot with the help of `ggplot2::geom_pointrange()`.

```{r, fig.width = 4.5, fig.height = 1.25}
tibble(model = c("b6.11", "b6.12", "b6.13", "b6.14"),
       waic = c(w.b6.11$waic, w.b6.12$waic, w.b6.13$waic, w.b6.14$waic),
       se = c(w.b6.11$se_waic, w.b6.12$se_waic, w.b6.13$se_waic, w.b6.14$se_waic)) %>%
  
  ggplot() +
  theme_classic() +
  geom_pointrange(aes(x = model, y = waic, 
                      ymin = waic - se, 
                      ymax = waic + se),
                  shape = 21, color = "plum4", fill = "plum") +
  coord_flip() +
  labs(x = NULL, y = NULL,
       title = "My custom WAIC plot") +
  theme(text = element_text(family = "Courier"),
        axis.ticks.y = element_blank())
```

This is as good a place as any to point out that brms also supports the LOO information criterion. It works similar to WAIC.

```{r, message = F, warning = F}
LOO(b6.11)

loo(b6.11)
```

For computing WAIC and LOO values, brms uses functions from the [loo package](https://cran.r-project.org/web/packages/loo/index.html). [This vignette](https://cran.r-project.org/web/packages/loo/vignettes/loo-example.html) is a fine place to learn more about the loo package and the LOO information criterion.

####6.5.1.2. Comparing estimates.

The brms package doesn't have anything like rethinking's `coeftab()` function. However, one can get that information with a little ingenuity. For this, we'll employ the [broom package](https://cran.r-project.org/web/packages/broom/index.html), which provides an array of convenience functions to convert statistical analysis summaries into tidy data objects. Here, we'll employ the `tidy()` function, which will save the summary statistics for our model parameters. For example, this is what it will produce for the full model, `b6.14`.

```{r, warning = F, message = F}
# install.packages("broom", dependendcies = T)
library(broom)

tidy(b6.14)
```

Note, `tidy()` also grabs the log posterior (i.e., "lp__"), which we'll exclude for our purposes. With a `rbind()` and a little indexing, we can save the summaries for all four models in a single tibble.

```{r}
my_coef_tab <-
  rbind(tidy(b6.11), tidy(b6.12), tidy(b6.13), tidy(b6.14)) %>%
  mutate(model = c(rep("b6.11", times = nrow(tidy(b6.11))),
                   rep("b6.12", times = nrow(tidy(b6.12))),
                   rep("b6.13", times = nrow(tidy(b6.13))),
                   rep("b6.14", times = nrow(tidy(b6.14))))
         ) %>%
  filter(term != "lp__") %>%
  select(model, everything())

head(my_coef_tab)
```

Just a little more work and we'll have a table analogous to the one McElreath produced with his `coef_tab()` function.

```{r}
my_coef_tab %>%
  # Learn more about dplyr::complete() here: https://rdrr.io/cran/tidyr/man/expand.html
  complete(term = distinct(., term), model) %>%
  select(model, term, estimate) %>%
  mutate(estimate = round(estimate, digits = 2)) %>%
  spread(key = model, value = estimate)
```

I'm also not aware of an efficient way in brms to reproduce Figure 6.12 for which McElreath nested his `coeftab()` argument in a `plot()` argument. However, one can build something similar by hand with a little data wrangling.

```{r, fig.width = 4, fig.height = 3, warning = F}
p11 <- posterior_samples(b6.11)
p12 <- posterior_samples(b6.12)
p13 <- posterior_samples(b6.13)
p14 <- posterior_samples(b6.14)

# This block is just for intermediary information
# colnames(p11)
# colnames(p12)
# colnames(p13)
# colnames(p14)

# Here we put it all together
tibble(mdn = c(NA, median(p11[, 1]), median(p12[, 1]), median(p13[, 1]), median(p14[, 1]),
               NA, NA, median(p12[, 2]), NA, median(p14[, 2]),
               NA, median(p11[, 2]), NA, median(p13[, 2]), NA,
               NA, median(p11[, 2]), median(p12[, 3]), median(p13[, 3]), median(p14[, 4])),
       sd  = c(NA, sd(p11[, 1]), sd(p12[, 1]), sd(p13[, 1]), sd(p14[, 1]),
               NA, NA, sd(p12[, 2]), NA, sd(p14[, 2]),
               NA, sd(p11[, 2]), NA, sd(p13[, 2]), NA,
               NA, sd(p11[, 2]), sd(p12[, 3]), sd(p13[, 3]), sd(p14[, 4])),
       order = c(20:1)) %>%
  
  ggplot(aes(x = mdn, y = order)) +
  theme_classic() +
  geom_hline(yintercept = 0, color = "plum4", alpha = 1/8) +
  geom_pointrange(aes(x = order, y = mdn, 
                      ymin = mdn - sd, 
                      ymax = mdn + sd),
                  shape = 21, color = "plum4", fill = "plum") +
  scale_x_continuous(breaks = 20:1,
                     labels = c("intercept", 11:14,
                                "neocortex", 11:14,
                                "logmass", 11:14,
                                "sigma", 11:14)) +
  coord_flip() +
  labs(x = NULL, y = NULL,
       title = "My custom coeftab() plot") +
  theme(text = element_text(family = "Courier"),
        axis.ticks.y = element_blank())
```

Making that plot entailed a lot of hand typing values in the tibble, which just begs for human error. If possible, it's better to use functions in a principled way to produce the results. Below is such an attempt.

```{r, message = F, warning = F, fig.height = 3, fig.width = 4}
my_coef_tab <-
  my_coef_tab %>%
  complete(term = distinct(., term), model) %>%
  rbind(
     tibble(
       model = NA,
       term = c("b_logmass", "b_neocortex", "sigma", "b_Intercept"),
       estimate = NA,
       std.error = NA,
       lower = NA,
       upper = NA)) %>%
  mutate(axis = ifelse(is.na(model), term, model),
         model = factor(model, levels = c("b6.11", "b6.12", "b6.13", "b6.14")),
         term = factor(term, levels = c("b_logmass", "b_neocortex", "sigma", "b_Intercept", NA))) %>%
  arrange(term, model) %>%
  mutate(axis_order = letters[1:20],
         axis = ifelse(str_detect(axis, "b6."), str_c("      ", axis), axis))
  
ggplot(data = my_coef_tab,
       aes(x = axis_order,
           y = estimate,
           ymin = lower,
           ymax = upper)) +
  theme_classic() +
  geom_hline(yintercept = 0, color = "plum4", alpha = 1/8) +
  geom_pointrange(shape = 21, color = "plum4", fill = "plum") +
  scale_x_discrete(NULL, labels = my_coef_tab$axis) +
  ggtitle("My other coeftab() plot") +
  coord_flip() +
  theme(text = element_text(family = "Courier"),
        panel.grid = element_blank(),
        axis.ticks.y = element_blank(),
        axis.text.y = element_text(hjust = 0))
```

I'm sure there are better ways to do this. Have at it.

```{r}
library(tidybayes)
models <- list(b6.11 = b6.11, b6.12 = b6.12, b6.13 = b6.13, b6.14 = b6.14)
(df <- tibble(name = names(models), model = models) %>% 
  mutate(coef_broom = model %>% map(.f = tidy)) %>% 
    unnest(coef_broom) %>% 
    filter(term != "lp__")
)

df %>% ggplot() +
  ggstance::geom_pointrangeh(aes(x = estimate, xmin = lower, xmax = upper, y = name)) + 
  geom_vline(xintercept =  0, linetype = "dashed") +
  facet_wrap(~ term, ncol = 1)


# bind_rows(linear_estimates, bayes_estimates) %>%
#   ggplot(aes(y = condition, x = estimate, xmin = conf.low, xmax = conf.high, color = model)) +
#   geom_pointrangeh(position = position_dodgev(height = .3))

```
###6.5.2. Model averaging.

Within the current brms framework, you can do model-averaged predictions with the `pp_average()` function. The default weighting scheme is with the LOO. Here we'll use the `weights = "waic"` argument to match McElreath's method in the text. Because `pp_average()` yields a matrix, we'll want to convert it to a tibble before feeding it into ggplot2.

```{r, fig.width = 3.5, fig.height = 3}
nd <- 
  tibble(neocortex = seq(from = .5, to = .8, length.out = 30),
         mass = rep(4.5, times = 30))

ftd <-
  fitted(b6.14, newdata = nd) %>%
  as_tibble() %>%
  bind_cols(nd)

pp_average(b6.11, b6.12, b6.13, b6.14,
           weights = "waic",
           method = "fitted",  # for new data predictions, use method = "predict"
           newdata = nd) %>%
  as_tibble() %>%
  bind_cols(nd) %>%
  
  ggplot(aes(x = neocortex, y = Estimate)) +
  theme_classic() +
  geom_ribbon(aes(ymin = `2.5%ile`, ymax = `97.5%ile`), 
              fill = "plum", alpha = 1/3) +
  geom_line(color = "plum2") +
  geom_ribbon(data = ftd, aes(ymin = `2.5%ile`, ymax = `97.5%ile`),
              fill = "transparent", color = "plum3", linetype = 2) +
  geom_line(data = ftd,
              color = "plum3", linetype = 2) +
  geom_point(data = d, aes(x = neocortex, y = kcal.per.g), 
             size = 2, color = "plum4") +
  labs(y = "kcal.per.g") +
  coord_cartesian(xlim = range(d$neocortex), 
                  ylim = range(d$kcal.per.g)) +
  theme(text = element_text(family = "Courier"))
```

**Bonus**: *R*^2^ talk

At the beginning of the chapter (pp. 167--168), McElreath briefly introduced *R*^2^ as a popular way to assess the variance explained in a model. He pooh-poohed it because of its tendency to overfit. It's also limited in that it doesn't generalize well outside of the single-level Gaussian framework. However, if you should find yourself in a situation where *R*^2^ suits your purposes, the brms `bayes_R2()` function might be of use. Simply feeding a model brm fit object into `bayes_R2()` will return the posterior mean, SD, and 95% intervals. For example:

```{r}
bayes_R2(b6.14) %>% round(digits = 3)
```

With just a little data processing, you can get a table of each of models' *R*^2^ `Estimate`.

```{r}
rbind(bayes_R2(b6.11), 
      bayes_R2(b6.12), 
      bayes_R2(b6.13), 
      bayes_R2(b6.14)) %>%
  as_tibble() %>%
  mutate(model = c("b6.11", "b6.12", "b6.13", "b6.14"),
         r_square_posterior_mean = round(Estimate, digits = 2)) %>%
  select(model, r_square_posterior_mean)
```

If you want the full distribution of the *R*^2^, you’ll need to add a `summary = F` argument. Note how this returns a numeric vector.

```{r}
b6.13.R2 <- bayes_R2(b6.13, summary = F)

b6.13.R2 %>%
  glimpse()
```

If you want to use these in ggplot2, you’ll need to put them in tibbles or data frames. Here we do so for two of our model fits.

```{r, fig.width = 3.5, fig.height = 3}
# model b6.13
b6.13.R2 <- 
  bayes_R2(b6.13, summary = F) %>%
  as_tibble() %>%
  rename(R2.13 = R2)

# model b6.14
b6.14.R2 <- 
  bayes_R2(b6.14, summary = F) %>%
  as_tibble() %>%
  rename(R2.14 = R2)

# Let's put them in the same data object
combined_R2s <-
  bind_cols(b6.13.R2, b6.14.R2) %>%
  mutate(dif = R2.14 - R2.13)

# A simple density plot
combined_R2s %>%
  ggplot(aes(x = R2.13)) +
  theme_classic() +
  geom_density(size = 0, fill = "plum1", alpha = 2/3) +
  geom_density(aes(x = R2.14),
               size = 0, fill = "plum2", alpha = 2/3) +
  scale_y_continuous(NULL, breaks = NULL) +
  coord_cartesian(xlim = 0:1) +
  labs(x = NULL,
       title = expression(paste(italic("R")^{2}, " distributions")),
       subtitle = "Going from left to right, these are for\nmodels b6.13 and b6.14.") +
  theme(text = element_text(family = "Courier"))
```

If you do your work in a field where folks use *R*^2^ change, you might do that with a simple difference score, which we computed above with `mutate(dif = R2.14 - R2.13)`. Here's the *R*^2^ change (i.e., `dif`) plot:

```{r, fig.width = 3.5, fig.height = 3}
combined_R2s %>%
  ggplot(aes(x = dif)) +
  theme_classic() +
  geom_density(size = 0, fill = "plum") +
  geom_vline(xintercept = quantile(combined_R2s$dif, 
                                   probs = c(.025, .5, .975)),
             color = "white", size = c(1/2, 1, 1/2)) +
  scale_y_continuous(NULL, breaks = NULL) +
  labs(x = expression(paste(Delta, italic("R")^{2})),
       subtitle = "This is how much more variance, in terms\nof %, model b6.14 explained compared to\nmodel b6.13. The white lines are the\nposterior median and 95% percentiles.") +
  theme(text = element_text(family = "Courier"))
```

The brms package did not get these *R*^2^ values by traditional method used in, say, ordinary least squares estimation. To learn more about how the Bayesian *R*^2^ sausage is made, check out the paper by [Gelman, Goodrich, Gabry, and Ali](https://github.com/jgabry/bayes_R2/blob/master/bayes_R2.pdf).

```{r, echo = F}
rm(d, InitsList, Inits, b6.8, dfLL, cars, b, dfmean, lppd, dfvar, pwaic, b6.11, b6.12, b6.13, b6.14, w.b6.11, w.b6.12, w.b6.13, w.b6.14, my_coef_tab, p11, p12, p13, p14, nd, ftd, b6.13.R2, b6.14.R2, combined_R2s)
```

Note. The analyses in this document were done with:

* R          3.4.3
* RStudio    1.1.364
* rmarkdown  1.8
* tidyverse  1.2.1
* ggrepel    0.7.0
* brms       2.1.8
* rethinking 1.59
* rstan      2.17.3
* broom      0.4.3

##References
McElreath, R. (2016). *Statistical rethinking: A Bayesian course with examples in R and Stan.* Chapman & Hall/CRC Press.


# Answers

## easy

1: information entropy:
- measure of uncertainty is continous. Small cahnges prob -> small change uncertainty
- uncertaintyt increases as possible evenst increase. 
- uncertainty is additive


```{r}
# 2 - E log(p)
p = 0.9
-p*log(p) + (1-p) * log(1-p)

# 3
p = c(.2,.25,.25,.3)
-sum(p*log(p))

# 4
p = c(1/3,1/3,1/3)
-sum(p*log(p))
```


## medium

### 1 
aic in dic in waic

aic = d_train + 2p
assumes flat priors or overwhelmed by likelihood
posterior is approx multivar gauusian
sample size much greater than number parametres

dic = 2*average deviane - deviance at posterior mean
also assumes posterior is approx multivar gaussian
also assumes sample size >> number parameters. 
Note: doesn know how to handle priors. 

waic = -2* (  (lppd = )total across observations of the log of the average likelihood of each observation - 
                       total across observations of the variance of the log probability of each observation)
                       
does not require approx multivar gaussian posterior

### 2
Either you select 1 or you use ensemble. Model uncertainty is lost under selection

### 3
information criterion increases with number of observations since it takes the sum over observations. 

### 4
Flat priors are closest to anything. Concentrated priors offer more opportunity for surprise. 
effective number of parameters estimates the difference between in sample performance and out of sample performance. 
with more concentrated priors in sample performance will be smaller, but out of sample perforance is usually higher. 
Therefore the differene (effective number of parameters) becomes smaller when using more concentrated priors. Model becomes less flexible

### 5
see 4. Less excitable by the data. 

### 6 
More informative priors lead to a bigger kl divergence between q (used) and p(real). You need more data to cross the distance. 


## hard

github issue for brms
```{r}
library(rethinking)
library(tidyverse)
library(brms)


data(Howell1)
d <- Howell1
d$age <- (d$age - mean(d$age))/sd(d$age)
i <- sample(1:nrow(d),size=nrow(d)/2)
d1 <- d[ i , ]


formulas <- list(
  m1 = height ~ 1 + age,
  m2 = height ~ 1 + age + I(age^2))

df <- tibble( 
  name = names(formulas),
  formulas = formulas
  ) %>% 
  mutate(model = formulas %>% purrr::map( 
    .f = brm, 
      data = d1, 
      family = gaussian,
      prior = c(set_prior("normal(0, 100)", class = "Intercept"),
                set_prior("normal(0, 10)", class = "b"),
                set_prior("cauchy(0, 1)", class = "sigma")),
      chains = 2, iter = 2000, warmup = 1000, cores = 2)
    )

m1_model <- df$model[[1]]
m2_model <- df$model[[2]]
brms::waic(m1_model, m2_model)
invoke(brms::waic, .x = list(m1_model, m2_model)) # correct values, but names are wrong. 
invoke(brms::waic, .x = list(m1 = m1_model, m2 = m2_model)) # does not work 
# returns error: Error in split_dots(x, ..., model_names = model_names) : argument "x" is missing, with no default
invoke(brms::waic, .x = df$model) # preferred solution, but does not work. 
# returns error: Error in split_dots(x, ..., model_names = model_names) : argument "x" is missing, with no default

df <- df %>% dplyr::mutate(
  waic = model %>% purrr::map(.f = brms::waic))
m1_waic <- df$waic[[1]]
m2_waic <- df$waic[[2]]

brms::compare_ic(m1_waic, m2_waic) 
invoke(compare_ic, .x = df$waic)
```




```{r}
library(rethinking)
library(tidyverse)
library(brms)
library(broom)
library(tidybayes)

data(Howell1)
d <- Howell1
d$age <- (d$age - mean(d$age))/sd(d$age)
set.seed( 1000 )
i <- sample(1:nrow(d),size=nrow(d)/2)
d1 <- d[ i , ]
d2 <- d[ -i , ]

```


```{r}

multi_formula_brm <- function(...) {
  model <- NULL
  function(form){
    if (is.null(model)){
      model <<-  brm(formula = form, ...)
      model
    } else {
      update(model, formula. = form)
    }
  }
}
```

```{r}
formulas <- list(
  m1 = height ~ 1 + age,
  m2 = height ~ 1 + age + I(age^2),
  m3 = height ~ 1 + age + I(age^2) + I(age^3),
  m4 = height ~ 1 + age + I(age^2) + I(age^3) + I(age^4),
  m5 = height ~ 1 + age + I(age^2) + I(age^3) + I(age^4) + I(age^5),
  m6 = height ~ 1 + age + I(age^2) + I(age^3) + I(age^4) + I(age^5) + I(age^6)
)
  
df <- tibble( 
  name = names(formulas),
  form = formulas
  ) %>% 
  mutate(model = form %>% purrr::map(
    .f = multi_formula_brm(
      data = d1, 
      family = gaussian,
      prior = c(set_prior("normal(0, 100)", class = "Intercept"),
                set_prior("normal(0, 10)", class = "b"),
                set_prior("cauchy(0, 1)", class = "sigma")),
      chains = 2, iter = 2000, warmup = 1000, cores = 2))
      )

df <- df %>% dplyr::mutate(
  waic = model %>% purrr::map(.f = brms::waic),
  coef_broom = model %>% purrr::map(.f = broom::tidy)  
  ) 
```


```{r}

  




  

df 

df %>% 
  unnest(coef_broom) %>% 
  filter(term != "lp__") %>% 
  ggplot() +
  ggstance::geom_pointrangeh(aes(x = estimate, xmin = lower, xmax = upper, y = name)) + 
  geom_vline(xintercept =  0, linetype = "dashed") +
  facet_wrap(~ term, ncol = 1)
```

```{r}
brms::waic(df$model[[1]], df$model[[2]],df$model[[3]],df$model[[4]],df$model[[5]],df$model[[6]])

waic_wrapper <- function(...) {
  dots <- list(...)
  if (!"x" %in% names(dots)) {
    names(dots)[1] <- "x"
  }
  do.call(brms::waic, dots)
}

invoke(waic_wrapper, .x = df$model, model_names = df$name)
# waic_wrapper(df$model)
```

```{r}
df$waic

# pp_average(bf$waic,
#            weights = "waic",
#            method = "fitted")  # for new data predictions, use method = "predi
```
6h2 attempt 1
```{r}

add_fitted_and_predicted_samples <- function(newdata, model, ...){
  list(estimate = add_fitted_samples, pred = add_predicted_samples ) %>% 
    invoke_map(.f = ., .x = list(list(newdata = newdata,  model = model, ...))) %$% 
    full_join(x = estimate, y = pred) %>% ungroup()
}

add_fitted_and_predicted_samples(newdata = d1, model = m1_model, n = 2) %>% 
  ggplot() + 
  stat_lineribbon(aes( x = area, y = pred), alpha = .3, .prob = c(.)) + 
  stat_lineribbon(aes( x = area, y = estimate), alpha = .6, .prob = c(.89)) + 
  ggplot(data = d %>% 
           data_grid(groupsize = seq_range(groupsize, n = 101), 
                     area = mean(area)) %>% 
           add_fitted_and_predicted_samples(model = m5h2)) + 
  stat_lineribbon(aes( x = groupsize, y = pred), alpha = .3, .prob = c(.89)) + 
  stat_lineribbon(aes( x = groupsize, y = estimate), alpha = .6, .prob = c(.89)) 
```

6h2 attempt 2
```{r}
overlay_predicted_distribution <- function( data_for_sample, d, predictor, predicted, model){  # also y and model
  x_var <- rlang::enquo(predictor)
  x_name <- rlang::quo_name(x_var)
  y_var <- rlang::enquo(predicted)
  

  data_for_sample %>%
    # data_grid(!!x_name := seq_range(!!x_var, n = 101)) %>% 
    add_predicted_samples(model = model, n = 100) %>% ungroup() %>%
    ggplot() +
    geom_point(data = d, aes_string(x = rlang::quo_text(x_var), y = rlang::quo_text(y_var) )) + 
    stat_lineribbon(aes_string(x = rlang::quo_text(x_var), y = "pred"), alpha = 0.5, .prob = c(.95)) +
    theme(legend.position="none")
}

library(patchwork)
library(modelr)


d1 %>% data_grid(age = seq_range(age, n = 50)) %>% overlay_predicted_distribution(d1, age, height, df$model[[1]]) 
d1 %>% data_grid(age = seq_range(age, n = 50)) %>% overlay_predicted_distribution(d1, age, height, df$model[[2]]) 
d1 %>% data_grid(age = seq_range(age, n = 50)) %>% overlay_predicted_distribution(d1, age, height, df$model[[3]]) 
d1 %>% data_grid(age = seq_range(age, n = 50)) %>% overlay_predicted_distribution(d1, age, height, df$model[[4]]) 
d1 %>% data_grid(age = seq_range(age, n = 50)) %>% overlay_predicted_distribution(d1, age, height, df$model[[5]]) 
d1 %>% data_grid(age = seq_range(age, n = 50)) %>% overlay_predicted_distribution(d1, age, height, df$model[[6]]) 

```
6h3

```{r}
brms_fn_wrapper <- function(fn, ...) {
  dots <- list(...)
  if (!"x" %in% names(dots)) {
    names(dots)[1] <- "x"
  }
  do.call(fn, dots)
}


invoke(brms_fn_wrapper, .x = df$model, fn = brms::loo_model_weights, model_names = df$name) -> tmp

df <- df %>% mutate(
  loo2_weight = as.array(tmp) ,
  pred_samples = map(.f = add_predicted_samples, 
                     .x = model,
                     newdata = d1 %>% data_grid(age = seq_range(age, n = 50)) %>% ungroup(),
  sampled_pred_samples = map2(.x = pred_samples, 
                              .y = loo2_weight,
                              .f = sample_frac) %>% ungroup()
    )
  )
df

df %>% rowwise %>% do(sampled_pred_samples = sample_frac(.$pred_samples, .$loo2_weight)) -> tmp3   

tmp3 %>% unnest() %>% ggplot() + stat_lineribbon(aes(x = age, y = pred), alpha = 0.5, .prob = c(.95) ) + geom_point(data = d1, aes(x = age, y = height))


# map_dfr(.x = df %>% pull(pred_samples), .f = )
# 
# 
# 
# sample_frac(tbl, size = 1, replace = FALSE, weight = NULL, .env = NULL)


(invoke(brms_fn_wrapper, .x = df$model, fn = brms::pp_average, model_names = df$name, weights = "loo2", 
       summary = TRUE, newdata = d1 %>% data_grid(age = seq_range(age, n = 50))) -> model_averaged_pred)

model_averaged_pred %>% as_tibble() %>% 
  mutate(age_val = d1 %>% data_grid(age = seq_range(age, n = 50)) %>% pull(age)) %>% 
  ggplot() + 
  geom_lineribbon(aes(x = age_val, y = Estimate, ymin = Q2.5, ymax = Q97.5, fill = c(0.95)))


# not done, I'll write a tidybayes style function, if this com
df
```
I used loo instead of waic. The effect is wider confidence interval due to added model uncertainty. 

6h4
```{r}

df <- df %>% mutate(
  waic_score = map_dbl(.x = waic,  .f = ~ pluck(.x , "estimates", 3)),
  dwaic = waic_score - min(waic_score),
  deviance = map_dbl(.x = model, .f = ~ log_lik(object = .x, newdata = d2) %>% as_tibble() %>% summarise_all(mean) %>% sum() %*% -2),
  ddeviance = deviance - min(deviance)
)
df


```
waic does a good job of estimating the ordering of deviance

6h6

```{r}

df_6h6flat <- tibble( 
  name = names(formulas),
  form = formulas
  ) %>% 
  mutate(
    model = form %>% 
      purrr::map(
        .f = multi_formula_brm(
          data = d1, 
          family = gaussian,
          prior = c(set_prior("normal(0, 100)", class = "Intercept"),
                    set_prior("normal(0, 50)", class = "b"),
                    set_prior("cauchy(0, 1)", class = "sigma")),
          chains = 2, iter = 2000, warmup = 1000, cores = 2)),
    coefficient_tibble = model %>% purrr::map(.f = broom::tidy) 
      )

df_6h6flat %>% unnest(coefficient_tibble) %>% filter(term != "lp__") %>% ggplot() +
  ggstance::geom_pointrangeh(aes(x = estimate, xmin = lower, xmax = upper, y = name)) + 
  geom_vline(xintercept =  0, linetype = "dashed") +
  facet_wrap(~ term, ncol = 1)


df_6h6flat <- df_6h6flat %>% 
  mutate(
    waic = model %>% purrr::map(.f = brms::waic),
    waic_score = map_dbl(.x = waic,  .f = ~ pluck(.x , "estimates", 3)),
      dwaic = waic_score - min(waic_score),
    deviance = map_dbl(.x = model, .f = ~ log_lik(object = .x, newdata = d2) %>% as_tibble() %>% summarise_all(mean) %>% sum() %*% -2),
    ddeviance = deviance - min(deviance)
)
df_6h6flat
```


```{r}

df_6h6 <- tibble( 
  name = names(formulas),
  form = formulas
  ) %>% 
  mutate(
    model = form %>% 
      purrr::map(
        .f = multi_formula_brm(
          data = d1, 
          family = gaussian,
          prior = c(set_prior("normal(0, 100)", class = "Intercept"),
                    set_prior("normal(0, 5)", class = "b"),
                    set_prior("cauchy(0, 1)", class = "sigma")),
          chains = 2, iter = 2000, warmup = 1000, cores = 2)),
    coefficient_tibble = model %>% purrr::map(.f = broom::tidy) 
      )

df_6h6 %>% unnest(coefficient_tibble) %>% filter(term != "lp__") %>% ggplot() +
  ggstance::geom_pointrangeh(aes(x = estimate, xmin = lower, xmax = upper, y = name)) + 
  geom_vline(xintercept =  0, linetype = "dashed") +
  facet_wrap(~ term, ncol = 1)


df_6h6 <- df_6h6 %>% 
  mutate(
    deviance = map_dbl(.x = model, .f = ~ log_lik(object = .x, newdata = d2) %>% as_tibble() %>% summarise_all(mean) %>% sum() %*% -2),
    ddeviance = deviance - min(deviance)
)
df_6h6

# map(.x = df_6h6$model , .f = summary)
```

I think the previous priors were already too small to see the intended result. I see from 6h6flat that the ddeviance of models with many parameters is greater with flat priors. Probably because the model is less restricted it can overfit the dataset more, thus lowering out of sample prediction. Therefor the out of sample data is more surprising to the overfitted models, thats why higher deviance.
### TODO

- Use psis-loo http://mc-stan.org/loo/articles/loo2-weights.html with brms. loo::compare  http://mc-stan.org/loo/articles/loo2-example.html
- Create a closure function that if a model is not fitted it fits it, otherwise it uses the already fitted model and updates it. 
- Is bayesplot handy?
- varaible selection package try it out https://cran.r-project.org/web/packages/projpred/vignettes/quickstart.html

model